"""
æœ€åŸå§‹ã€æœ€ç®€å•çš„ Playwright ä½¿ç”¨æ–¹æ¡ˆ
ä¸åšä»»ä½•ä¼ªè£…ã€ä¸è®¾ç½®å¤´éƒ¨ã€ä¸æ³¨å…¥ JavaScript
ä¸ä¿å­˜/åŠ è½½ Cookieï¼Œå®Œå…¨ç‹¬ç«‹çš„æµè§ˆå™¨ä¼šè¯
å®Œå…¨æ¨¡æ‹ŸçœŸå®ç”¨æˆ·ä½¿ç”¨æµè§ˆå™¨çš„è¡Œä¸º

è¿™æ˜¯å®Œæ•´çš„ utils.py æ›¿ä»£ç‰ˆæœ¬ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„å‡½æ•°
"""

import json
import os
from pathlib import Path
import re
import requests
import time
from urllib import parse

from config import CONF

video_index_cache_filename = "./jable_index_cache.json"

HEADERS = CONF.get("headers")

logged = False


def get_video_ids_map_from_cache():
    cache = {}
    if os.path.exists(video_index_cache_filename):
        with open(video_index_cache_filename, 'r', encoding='utf-8') as f:
            cache = json.load(f)

    return cache


def _add_proxy(query_param, retry_index, ignore_proxy):
    if not ignore_proxy or retry_index > 1:
        proxies_config = CONF.get('proxies', None)
        if proxies_config and 'http' in proxies_config and 'https' in proxies_config:
            query_param['proxies'] = proxies_config


def requests_with_retry(url, headers=HEADERS, timeout=20, retry=5, ignore_proxy=False):
    query_param = {
        'headers': headers,
        'timeout': timeout
    }

    for i in range(1, retry+1):
        try:
            _add_proxy(query_param, i, ignore_proxy)
            response = requests.get(url, **query_param)
        except Exception as e:
            if i == 1 and ignore_proxy:
                continue
            if i < retry:
                wait_time = min(10 * i, 30)
                print(f"    âš  è¯·æ±‚å¤±è´¥ (å°è¯• {i}/{retry}): {str(e)[:80]}")
                print(f"    â³ {wait_time}ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                print(f"    âœ— è¯·æ±‚æœ€ç»ˆå¤±è´¥: {str(e)[:80]}")
            continue

        if str(response.status_code).startswith('2'):
            return response
        else:
            # å¯¹äºæ°¸ä¹…æ€§é”™è¯¯ï¼ˆ404, 410ï¼‰ï¼Œä¸é‡è¯•
            if response.status_code in [404, 410]:
                if response.status_code == 410:
                    print(f"    âœ— HTTP 410 Gone: èµ„æºå·²è¿‡æœŸæˆ–æ°¸ä¹…æ¶ˆå¤±")
                    print(f"    ğŸ’¡ æç¤º: é“¾æ¥å¯èƒ½åŒ…å«æ—¶é—´æˆ³å·²è¿‡æœŸï¼Œæˆ–æœåŠ¡å™¨æ—¶é—´ä¸å‡†ç¡®")
                else:
                    print(f"    âœ— HTTP 404: èµ„æºä¸å­˜åœ¨")
                raise Exception(f"HTTP {response.status_code}: {url}")

            # å¯¹äºå…¶ä»–é”™è¯¯ï¼Œé‡è¯•
            if i < retry:
                wait_time = min(10 * i, 30)
                print(f"    âš  HTTPé”™è¯¯ (å°è¯• {i}/{retry}): çŠ¶æ€ç  {response.status_code}")
                print(f"    â³ {wait_time}ç§’åé‡è¯•...")
                time.sleep(wait_time)
            continue
    raise Exception("%s exceed max retry time %s." % (url, retry))


def scrapingant_requests_get(url, retry=5) -> str:
    global logged
    if not CONF.get('sa_token'):
        if not logged:
            logged = True
            print("You need to go to https://app.scrapingant.com/ website to\n apply for a token and fill it in the sa_token field")
            print("Use local Playwright as a replacement.\n")
        print("  [Playwright] æ­£åœ¨è·å–è§†é¢‘é¡µé¢ä¿¡æ¯...")
        return get_response_from_playwright(url)

    query_param = {
        "timeout": 180
    }

    sa_api = 'https://api.scrapingant.com/v2/general'
    qParams = {'url': url, 'x-api-key': CONF.get('sa_token'), 'browser': 'false'}
    if CONF.get('sa_mode', None) == 'browser':
        qParams['browser'] = 'true'
    reqUrl = f'{sa_api}?{parse.urlencode(qParams)}'

    proxies_config = CONF.get('proxies', None)

    if proxies_config and 'http' in proxies_config and 'https' in proxies_config:
        query_param['proxies'] = proxies_config

    for i in range(1, retry+1):
        try:
            response = requests.get(reqUrl, **query_param)
        except Exception as e:
            if i == retry:
                print("Unexpected Error: %s" % e)
            time.sleep(120 * i)
            continue

        if str(response.status_code).startswith('2'):
            return response.text
        else:
            time.sleep(120 * i)
            continue
    raise Exception("%s exceed max retry time %s" % (url, retry))


def update_video_ids_cache(data):
    with open(video_index_cache_filename, 'w', encoding='utf8') as f:
        json.dump(data, f, ensure_ascii=False)


def get_local_video_list(path="./"):
    # ä¿®æ­£æ­£åˆ™ï¼šåŒ¹é…å®Œæ•´çš„è§†é¢‘ IDï¼ŒåŒ…æ‹¬æ‰€æœ‰åç¼€
    # æ ¼å¼: å­—æ¯æ•°å­—-æ•°å­—-å­—æ¯(å¯é€‰)ï¼Œä¾‹å¦‚ ssni-301-c, abc-123, xyz-456-d
    re_extractor = re.compile(r"[a-zA-Z0-9]{2,}-\d{3,}(?:-[a-zA-Z0-9]+)?")

    def extract_movie_id(full_name):
        foo = re_extractor.search(full_name)
        movie_id = None
        if foo:
            movie_id = foo.group(0).lower()
        return movie_id

    result = {extract_movie_id(foo.name) for foo in list(Path(path).rglob("*.mp4"))}
    if None in result:
        result.remove(None)

    return result


def get_response_from_playwright_simple(url, retry=3):
    """
    æœ€åŸå§‹çš„ Playwright ä½¿ç”¨æ–¹æ¡ˆ

    åŸåˆ™ï¼š
    - ä¸è®¾ç½®ä»»ä½•é¢å¤–çš„ HTTP å¤´éƒ¨ï¼ˆé™¤äº† Referer ç”¨äºåˆ†é¡µå¯¼èˆªï¼‰
    - ä¸æ³¨å…¥ä»»ä½• JavaScript ä»£ç 
    - ä¸åšä»»ä½•æµè§ˆå™¨æŒ‡çº¹ä¼ªè£…
    - ä¸å¼ºåˆ¶è®¾ç½® User-Agent
    - ä¸ä¿å­˜/åŠ è½½ Cookieï¼Œæ¯æ¬¡éƒ½æ˜¯å…¨æ–°ä¼šè¯
    - è®©æµè§ˆå™¨å®Œå…¨æŒ‰ç…§é»˜è®¤è¡Œä¸ºè¿è¡Œ
    - å”¯ä¸€åšçš„ï¼šä½¿ç”¨ç³»ç»Ÿæµè§ˆå™¨ï¼ˆå¦‚æœé…ç½®äº†ï¼‰

    Args:
        url: ç›®æ ‡ URL
        retry: é‡è¯•æ¬¡æ•°

    Returns:
        str: ç½‘é¡µ HTML å†…å®¹
    """
    from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError

    proxy = CONF.get('proxies', {}).get('http', None)
    headless_mode = CONF.get('playwright_headless', True)
    system_chrome_path = CONF.get('chrome_path', None)

    for attempt in range(1, retry + 1):
        try:
            with sync_playwright() as p:
                # æœ€ç®€å•çš„å¯åŠ¨é…ç½®
                launch_options = {
                    'headless': headless_mode,
                }

                # å¦‚æœé…ç½®äº†ç³»ç»Ÿæµè§ˆå™¨ï¼Œä½¿ç”¨ç³»ç»Ÿæµè§ˆå™¨
                if system_chrome_path and os.path.exists(system_chrome_path):
                    launch_options['executable_path'] = system_chrome_path
                    if attempt == 1:
                        print(f"  [Simple] ä½¿ç”¨ç³»ç»Ÿæµè§ˆå™¨: {system_chrome_path}")

                # å¯åŠ¨æµè§ˆå™¨
                if attempt == 1:
                    mode_text = "æ— å¤´æ¨¡å¼" if headless_mode else "æœ‰å¤´æ¨¡å¼"
                    print(f"  [Simple] å¯åŠ¨æµè§ˆå™¨ ({mode_text})...")
                    print(f"  [Simple] åŸå§‹æ¨¡å¼ï¼šä¸åšä»»ä½•ä¼ªè£…")

                browser = p.chromium.launch(**launch_options)

                if attempt == 1:
                    print(f"  [Simple] æµè§ˆå™¨ç‰ˆæœ¬: {browser.version}")

                try:
                    # æœ€ç®€å•çš„ä¸Šä¸‹æ–‡é…ç½® - åªé…ç½®ä»£ç†
                    context_options = {}

                    if proxy:
                        context_options['proxy'] = {'server': proxy}
                        if attempt == 1:
                            print(f"  [Simple] ä½¿ç”¨ä»£ç†: {proxy}")

                    context = browser.new_context(**context_options)

                    # è®¾ç½®åŸºç¡€çš„ Refererï¼ˆå¦‚æœ URL æœ‰å‚æ•°ï¼‰
                    # è¿™æ ·è®¿é—® ?from=1 æ—¶ä¼šå¸¦ä¸Š Refererï¼Œæ¨¡æ‹ŸçœŸå®çš„é¡µé¢å¯¼èˆª
                    from urllib.parse import urlparse, parse_qs
                    parsed = urlparse(url)
                    if parsed.query:  # å¦‚æœæœ‰æŸ¥è¯¢å‚æ•°
                        # åŸºç¡€ URLï¼ˆä¸å¸¦å‚æ•°ï¼‰ä½œä¸º Referer
                        base_url = f"{parsed.scheme}://{parsed.netloc}{parsed.path}"
                        context.set_extra_http_headers({
                            'Referer': base_url
                        })
                        if attempt == 1:
                            print(f"  [Simple] è®¾ç½® Referer: {base_url}")

                    # åˆ›å»ºé¡µé¢
                    page = context.new_page()

                    # ç›´æ¥è®¿é—® URL - ä¸åšä»»ä½•é¢å¤–æ“ä½œ
                    if attempt == 1:
                        print(f"  [Simple] æ­£åœ¨è®¿é—®: {url}")

                    page.goto(url, timeout=60000)

                    # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
                    if attempt == 1:
                        print(f"  [Simple] é¡µé¢åŠ è½½å®Œæˆ")

                    # ç®€å•ç­‰å¾…ä¸€ä¸‹ç¡®ä¿å†…å®¹åŠ è½½
                    page.wait_for_timeout(3000)

                    # è·å–é¡µé¢å†…å®¹
                    html = page.content()

                    # æ£€æŸ¥æ˜¯å¦é‡åˆ° Cloudflare
                    if 'Just a moment' in html or 'Verify you are human' in html or 'è«‹ç¨å€™' in html:
                        if attempt == 1:
                            print(f"  [Simple] æ£€æµ‹åˆ° Cloudflare éªŒè¯é¡µé¢")

                        # ç®€å•ç­‰å¾… - ä¸åšä»»ä½•æ¨¡æ‹Ÿ
                        if attempt == 1:
                            print(f"  [Simple] ç­‰å¾… Cloudflare è‡ªåŠ¨éªŒè¯...")

                        max_wait = 60  # å¢åŠ åˆ° 60 ç§’
                        for i in range(max_wait):
                            page.wait_for_timeout(1000)
                            html = page.content()

                            if 'Just a moment' not in html and 'Verify you are human' not in html and 'è«‹ç¨å€™' not in html:
                                print(f"  [Simple] âœ“ Cloudflare éªŒè¯é€šè¿‡ (ç­‰å¾… {i+1} ç§’)")
                                break

                            if (i + 1) % 10 == 0:
                                print(f"  [Simple] ä»åœ¨ç­‰å¾…... ({i+1}/{max_wait}ç§’)")

                        # æœ€åå†å–ä¸€æ¬¡å†…å®¹
                        html = page.content()

                    if attempt == 1:
                        print(f"  [Simple] å®Œæˆï¼HTML é•¿åº¦: {len(html)}")

                    return html

                finally:
                    browser.close()

        except Exception as e:
            print(f"  [Simple] é”™è¯¯ (å°è¯• {attempt}/{retry}): {str(e)[:200]}")
            if attempt == retry:
                raise Exception(f"Simple request failed after {retry} attempts: {str(e)}")
            time.sleep(3 * attempt)

    raise Exception(f"Simple request failed: {url}")


# å…¼å®¹æ€§ï¼šæä¾›å’ŒåŸæ¥ä¸€æ ·çš„å‡½æ•°å
get_response_from_playwright = get_response_from_playwright_simple


if __name__ == '__main__':
    # æµ‹è¯•
    print("æµ‹è¯•æœ€åŸå§‹çš„ Playwright æ–¹æ¡ˆ")
    print()

    test_url = "https://jable.tv/models/851cf1602f37c2611917b675f2d432c7/"

    try:
        html = get_response_from_playwright_simple(test_url)

        print()
        print("="*60)
        print("æµ‹è¯•ç»“æœ")
        print("="*60)

        if 'Just a moment' in html or 'Verify you are human' in html:
            print("âŒ ä»ç„¶é‡åˆ° Cloudflare éªŒè¯")
        else:
            print("âœ… æˆåŠŸè·å–é¡µé¢å†…å®¹ï¼")
            print(f"HTML é•¿åº¦: {len(html)}")

            # æ£€æŸ¥æ˜¯å¦æœ‰æ¼”å‘˜åç§°
            if 'h3-md mb-1' in html or 'video-img' in html:
                print("âœ“ é¡µé¢åŒ…å«æ­£å¸¸å†…å®¹")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
